# Image Caption Generator
The goal is to design an web application that covers all the functions of image description and provides an interface to the user. 
By using Deep Learning techniques the project performed:  

• Image Captioning: Recognising Different types of objects in an image and creating a 
  meaningful sentence that describes that image to visually impaired persons. 
    
• Text to speech conversion: Forgiving the result in audio form.

This project aims to develop software that can generate descriptive captions for images using neural networks language models. This project can act as a vision for visually impaired people, as it can identify nearby objects through the camera and give output in audio form. The application can provide a highly interactive platform for specially-abled people. 

It involves the dual techniques from computer vision to understand the content of the image and a language model from the field of natural language processing to turn the understanding of the image into words in the right order. Image captioning has various applications such as recommendations in editing applications, usage in virtual assistants, image indexing, for visually impaired persons, social media, and several other natural language processing applications.

At present images are annotated with human intervention and it becomes a nearly impossible task for huge commercial databases. The image database is given as input to a deep neural network (Convolutional Neural Network (CNN)) encoder for generating “thought vector” which extracts the features and nuances out of our image and RNN (Recurrent Neural Network) decoder is used to translate the features and objects given by our image to obtain a sequential, meaningful description of the image.
